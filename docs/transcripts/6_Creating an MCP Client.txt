
0:01 With your MCP server ready,
0:03 it's now time to create an MCP client inside your chatbot.
0:07 To let the chatbot communicate with the server and get access to the tool
0:11 definitions and results.
0:13 Let's have some fun!
0:14 Now that we've seen how to build a server with MCP,
0:18 let's go ahead and move past the inspector and build our own host
0:22 to contain a client to talk to our MCP server.
0:26 We're going to be working with the chatbot directly, but if you want to take
0:30 a look at other files like the server that we've made before, feel free to do so.
0:35 We're going to start by revisiting what we saw before in our chatbot example.
0:39 You're going to
0:39 see a lot of this code again, but we're going to layer on a little bit more
0:43 as we start bringing a client into the mix.
0:45 Everything you're seeing here we've seen before.
0:48 This is simply the ability to process a query
0:51 using Claude 3.7 Sonnet, as well as tool use.
0:55 We can see here that we're not actually defining any tools.
0:58 That's all being done in the server that we made in the last lesson.
1:03 Let's go ahead now and start talking about how to bring in
1:06 and create an MCP client.
1:08 I'm going to bring in a bit of code from the underlying MCP library,
1:13 because I want to talk through what's actually happening here.
1:16 If you remember, when we create an MCP client, which lives inside of a host,
1:22 we need to make sure that that client establishes a connection to an MCP server.
1:28 An important note here,
1:29 the code that we're looking at is slightly lower level.
1:32 You won't always find yourself
1:34 building clients from scratch, but it's really important
1:37 that when you see other tools like Claude desktop or Claude AI,
1:41 you have an idea of what's happening under the hood.
1:44 So if this code looks relatively intimidating, don't be too worried.
1:48 We'll go step by step.
1:49 The goal here is really to make sure you understand how clients are created
1:54 and how they establish connections to servers.
1:56 What we're seeing here are a few imports from the underlying MCP library,
2:02 to bring in the necessary classes, to establish a connection to a server,
2:07 as well as the ability to start a subprocess from the client.
2:11 So the first thing we're going to do here is establish the server
2:15 and the parameters necessary that we want to connect to.
2:18 And this is actually going to look pretty familiar. That scene command that we ran,
2:22 uv run Research Server dot py.
2:25 We're specifying here to let our client know how to start the server.
2:30 If there are any environment variables that we need, we can pass those in here.
2:35 The next step is to actually establish that connection
2:38 and launch the server as a subprocess.
2:41 Since we might not want this to be blocking, we're going to be making
2:44 use of async and await quite a bit in Python.
2:48 If you're not too familiar with that,
2:49 no worries, I'll walk you through what needs to be done here.
2:52 We're going to define a function called run, and we're going to set up
2:55 a context manager to first pass in the parameters
3:00 from our server and establish a connection as a subprocess.
3:04 Once we've established the server to connect to,
3:07 we're going to get access to a read and write stream
3:11 that we can then pass to a higher level class called the client session.
3:16 In this client session, when we pass the read and write stream,
3:20 we'll get access to an underlying connection
3:23 that allows us to make use of functionality
3:26 for listing tools, initializing connections,
3:29 and doing quite a bit more with other primitives.
3:32 The first thing we're going to do
3:33 is establish that handshake and initialize our session.
3:37 Well, then go ahead and list all of the available tools
3:41 that the server is providing.
3:43 Remember, the client's job is to query for tools
3:46 and take those tools and pass them to a large language model.
3:50 We'll make use of our chat loop functionality that we saw before.
3:53 And if there is a tool that needs to be invoked,
3:56 we'll go ahead and let the MCP server do that work.
4:00 So we're going to see a slightly different bit of code
4:03 for executing the underlying tool.
4:06 We're going to bring in the tools from the MCP server.
4:09 And if a tool needs to be executed,
4:12 we'll let the MCP server know what to do.
4:15 And we've defined all the code necessary
4:17 in the previous lesson for what happens when that tool is executed.
4:22 Since we're working in an async environment,
4:24 we're going to be moving past MCP dot run and using async IO dot run.
4:30 So with that in mind, let's put this all together.
4:32 We're going to go ahead and add our MCP client to our chatbot.
4:37 We're going to go ahead and write a file called MCP chatbot dot py.
4:42 Since this is what we're going to run in the terminal
4:45 to start interacting with our chatbot, we're going to bring in all of the imports
4:49 that you saw before alongside nest async IO, which is necessary for different
4:55 operating systems to work properly with the event loop in Python.
4:59 We're going to bring in any environment variables that we have
5:02 and then initialize our chatbot.
5:03 When we initialize our chatbot, we don't have a current session
5:08 and we don't have any tools available to us.
5:11 We're going to see that once we start establishing
5:13 the connection, these values will change.
5:16 Our process query looks very similar to above
5:19 with a slight difference of what happens when the tool needs to be invoked.
5:24 We're using the session established to go back
5:27 to the MCP server and execute the tool necessary.
5:31 We're then going to follow similar logic for appending a message
5:34 and making use of tool use that we've seen before.
5:37 Our chat loop as well is going to look very similar.
5:40 We're going to go ahead and keep running until someone types in quit
5:44 and process that particular query whenever data comes in.
5:48 To wrap this up, we're going to define a function called connect
5:51 to Server and Run, which does just that. Like we saw before,
5:56 we establish a connection to an MCP server.
5:59 We get access to the read and write stream and the underlying session
6:04 so that we can establish that connection, list the tools that we need,
6:08 and then take those tools and pass them for tool use in the model.
6:13 To wrap this up, we initialize our chatbot
6:16 and we call our connect to server and run function.
6:19 Inside of a __name__ equals __mean__
6:22 We run our main function using async IO.
6:25 So let's go ahead and run this code to create the necessary MCP chatbot.py file.
6:31 So let's go ahead and bring in our terminal.
6:34 And we'll see here I'm in the L5 directory.
6:37 I'm going to CD into the MCP project folder.
6:42 And if we take a look at what I have right here,
6:45 I have a virtual environment that already exists.
6:49 So I'm going to go ahead and start by activating
6:52 that virtual environment. Source dot venv bin activate.
6:56 We're also going to need a couple other dependencies to make this project work.
7:00 So I'll go ahead clear this and I'll add the Anthropic SDK,
7:06 the python-dotenv module
7:08 for environment variable access and nest async IO.
7:12 Once I add those dependencies, I should have everything necessary
7:16 to start my chatbot. Before I start the chatbot
7:19 let's just make sure we see how this is coming together.
7:21 When I type in uv run MCP chatbot dot py.
7:25 We are going to connect to our MCP server,
7:29 make use of the tools that are defined, past those tools to Claude,
7:34 and then create a nice interface for us to start talking with Claude,
7:38 to get access to those tools and any other data that we want.
7:42 We can see here that when there is a connection,
7:45 we're processing that request of list tools request.
7:48 This is the underlying functionality in the protocol
7:51 that allows me to pull in the tools necessary.
7:54 We've connected to the server
7:56 with the following tools and we can start talking to our chatbot.
7:59 We can always start with something simple.
8:01 Just make sure things are working.
8:03 A friendly query to greet our chatbot.
8:05 Now let's go ahead and make use of some of those tools that we have.
8:09 So I'll ask, can you search for papers around physics
8:15 and find just two of them for me?
8:18 What we're going to do here is make use of those particular tools that we have.
8:23 We're going to see here using the call tool request
8:26 that the MCP client is sending this data to the server.
8:30 The server is invoking that tool and returning it back to us.
8:34 We're then using Claude with that additional context
8:37 to return a nice summary to us.
8:40 While we've done a little bit of lower level programing to make this work,
8:44 we've started to build a foundation for something incredibly powerful.
8:48 We're going to first establish multiple client sessions
8:51 to allow for the use of many different MCP servers.
8:54 So these can all start to work together.
8:56 And then we're going to start layering on additional primitives
8:59 like resources and prompts.
9:01 To really see this work at a much larger scale.
9:04 See you in the next lesson.
9:06 And don't forget, if you ever want to get out of the chatbot, you can
9:09 always type quit.
